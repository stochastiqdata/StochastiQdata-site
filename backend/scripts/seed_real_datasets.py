"""
Script de peuplement de la base de donnÃ©es avec de vrais datasets actuariels.
Ces datasets sont des rÃ©fÃ©rences vers des sources externes (Kaggle, CAS, UCI, etc.)
Aucune donnÃ©e n'est stockÃ©e - uniquement les mÃ©tadonnÃ©es et liens.
"""

import os
import sys
from datetime import datetime, timezone

# Ajouter le rÃ©pertoire parent au path pour les imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from supabase import create_client
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_SERVICE_KEY = os.getenv("SUPABASE_SERVICE_KEY")

if not SUPABASE_URL or not SUPABASE_SERVICE_KEY:
    print("âŒ Erreur: SUPABASE_URL et SUPABASE_SERVICE_KEY doivent Ãªtre dÃ©finis dans .env")
    sys.exit(1)

# Client Supabase avec service role (bypass RLS)
supabase = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)

# ============================================
# Vrais datasets actuariels publics
# ============================================

REAL_DATASETS = [
    # ========== KAGGLE DATASETS ==========
    {
        "name": "French Motor Third-Party Liability Claims (freMTPL2freq)",
        "description": "Dataset classique de l'assurance automobile franÃ§aise. Contient 678 013 polices avec les caractÃ©ristiques du vÃ©hicule, du conducteur et l'historique des sinistres. IdÃ©al pour la modÃ©lisation de la frÃ©quence des sinistres avec GLM Poisson.",
        "source": "kaggle",
        "source_url": "https://www.kaggle.com/datasets/floser/french-motor-claims-datasets-fremtpl2freq",
        "tags": ["iard", "glm", "pricing"],
        "row_count": 678013,
        "column_count": 12,
        "file_size_mb": 45.2,
        "data_dictionary_url": "https://www.openml.org/search?type=data&sort=runs&id=41214&status=active",
        "modeling_types": ["regression", "classification"],
        "pivot_variables": ["exposure", "claim_amount", "policy_id"],
        "best_fit_models": ["glm", "xgboost", "lightgbm"],
    },
    {
        "name": "French Motor Third-Party Liability Severity (freMTPL2sev)",
        "description": "Dataset complÃ©mentaire au freMTPL2freq pour la modÃ©lisation du coÃ»t des sinistres. Contient les montants individuels des sinistres. UtilisÃ© avec GLM Gamma ou Tweedie pour le pricing.",
        "source": "kaggle",
        "source_url": "https://www.kaggle.com/datasets/floser/french-motor-claims-datasets-fremtpl2sev",
        "tags": ["iard", "glm", "pricing"],
        "row_count": 26639,
        "column_count": 2,
        "file_size_mb": 0.8,
        "data_dictionary_url": "https://www.openml.org/search?type=data&sort=runs&id=41215&status=active",
        "modeling_types": ["regression"],
        "pivot_variables": ["claim_amount", "claim_id"],
        "best_fit_models": ["glm", "xgboost", "lightgbm"],
    },
    {
        "name": "Health Insurance Cross Sell Prediction",
        "description": "Dataset pour prÃ©dire si un client d'assurance santÃ© serait intÃ©ressÃ© par une assurance vÃ©hicule. 381 109 clients avec caractÃ©ristiques dÃ©mographiques et historique d'assurance. Excellent pour le cross-selling en assurance.",
        "source": "kaggle",
        "source_url": "https://www.kaggle.com/datasets/anmolkumar/health-insurance-cross-sell-prediction",
        "tags": ["sante", "machine_learning"],
        "row_count": 381109,
        "column_count": 12,
        "file_size_mb": 25.3,
        "data_dictionary_url": "https://www.kaggle.com/datasets/anmolkumar/health-insurance-cross-sell-prediction",
        "modeling_types": ["classification"],
        "pivot_variables": ["policy_id"],
        "best_fit_models": ["xgboost", "lightgbm", "random_forest", "catboost"],
    },
    {
        "name": "Insurance Fraud Detection",
        "description": "Dataset de dÃ©tection de fraude en assurance automobile. Contient des sinistres avec indicateur de fraude. IdÃ©al pour dÃ©velopper des modÃ¨les de scoring anti-fraude.",
        "source": "kaggle",
        "source_url": "https://www.kaggle.com/datasets/shivamb/vehicle-claim-fraud-detection",
        "tags": ["iard", "fraude", "machine_learning"],
        "row_count": 15420,
        "column_count": 33,
        "file_size_mb": 3.2,
        "data_dictionary_url": "https://www.kaggle.com/datasets/shivamb/vehicle-claim-fraud-detection",
        "modeling_types": ["classification"],
        "pivot_variables": ["claim_id", "claim_amount"],
        "best_fit_models": ["xgboost", "random_forest", "lightgbm", "neural_network"],
    },
    {
        "name": "Medical Cost Personal Dataset",
        "description": "PrÃ©diction des coÃ»ts mÃ©dicaux individuels basÃ©e sur l'Ã¢ge, le sexe, l'IMC, le tabagisme et la rÃ©gion. Dataset simple mais trÃ¨s utilisÃ© pour l'introduction au pricing santÃ©.",
        "source": "kaggle",
        "source_url": "https://www.kaggle.com/datasets/mirichoi0218/insurance",
        "tags": ["sante", "glm", "pricing"],
        "row_count": 1338,
        "column_count": 7,
        "file_size_mb": 0.05,
        "data_dictionary_url": "https://www.kaggle.com/datasets/mirichoi0218/insurance",
        "modeling_types": ["regression"],
        "pivot_variables": ["claim_amount"],
        "best_fit_models": ["glm", "xgboost", "random_forest"],
    },
    {
        "name": "Porto Seguro Safe Driver Prediction",
        "description": "Competition Kaggle de Porto Seguro (assureur brÃ©silien). PrÃ©diction de la probabilitÃ© qu'un conducteur soumette une rÃ©clamation. Dataset anonymisÃ© avec variables catÃ©gorielles et continues.",
        "source": "kaggle",
        "source_url": "https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction",
        "tags": ["iard", "machine_learning", "pricing"],
        "row_count": 595212,
        "column_count": 59,
        "file_size_mb": 150.0,
        "data_dictionary_url": "https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/data",
        "modeling_types": ["classification"],
        "pivot_variables": ["policy_id"],
        "best_fit_models": ["xgboost", "lightgbm", "catboost", "neural_network"],
    },
    {
        "name": "Allstate Claims Severity",
        "description": "Competition Kaggle d'Allstate. PrÃ©diction de la sÃ©vÃ©ritÃ© des sinistres (coÃ»t). Variables anonymisÃ©es catÃ©gorielles et continues. Dataset de rÃ©fÃ©rence pour le pricing severity.",
        "source": "kaggle",
        "source_url": "https://www.kaggle.com/competitions/allstate-claims-severity",
        "tags": ["iard", "machine_learning", "pricing"],
        "row_count": 188318,
        "column_count": 132,
        "file_size_mb": 95.0,
        "data_dictionary_url": "https://www.kaggle.com/competitions/allstate-claims-severity/data",
        "modeling_types": ["regression"],
        "pivot_variables": ["claim_id", "claim_amount"],
        "best_fit_models": ["xgboost", "lightgbm", "catboost", "neural_network"],
    },
    {
        "name": "Life Insurance Assessment (Prudential)",
        "description": "Competition Kaggle de Prudential. Classification du niveau de risque pour l'assurance vie (8 classes). Variables mÃ©dicales et dÃ©mographiques anonymisÃ©es.",
        "source": "kaggle",
        "source_url": "https://www.kaggle.com/competitions/prudential-life-insurance-assessment",
        "tags": ["vie", "machine_learning"],
        "row_count": 59381,
        "column_count": 128,
        "file_size_mb": 35.0,
        "data_dictionary_url": "https://www.kaggle.com/competitions/prudential-life-insurance-assessment/data",
        "modeling_types": ["classification"],
        "pivot_variables": ["policy_id"],
        "best_fit_models": ["xgboost", "lightgbm", "random_forest", "catboost"],
    },

    # ========== CAS (Casualty Actuarial Society) ==========
    {
        "name": "CAS Loss Reserving Database - Commercial Auto",
        "description": "Triangles de sinistres de la CAS pour l'assurance automobile commerciale. DonnÃ©es historiques de 1988-1997. RÃ©fÃ©rence pour les mÃ©thodes de provisionnement (Chain-Ladder, Mack, BF).",
        "source": "other",
        "source_url": "https://www.casact.org/publications-research/research/research-resources/loss-reserving-data-pulled-naic-schedule-p",
        "tags": ["iard", "reserving"],
        "row_count": 200,
        "column_count": 15,
        "file_size_mb": 0.5,
        "data_dictionary_url": "https://www.casact.org/publications-research/research/research-resources/loss-reserving-data-pulled-naic-schedule-p",
        "modeling_types": ["time_series", "regression"],
        "pivot_variables": ["occurrence_date", "claim_amount"],
        "best_fit_models": ["chain_ladder", "mack", "bornhuetter_ferguson"],
    },
    {
        "name": "CAS Loss Reserving Database - Workers Compensation",
        "description": "Triangles de sinistres Workers Compensation de la CAS. IdÃ©al pour les Ã©tudes de dÃ©veloppement long-tail et la comparaison des mÃ©thodes stochastiques de rÃ©serves.",
        "source": "other",
        "source_url": "https://www.casact.org/publications-research/research/research-resources/loss-reserving-data-pulled-naic-schedule-p",
        "tags": ["iard", "reserving"],
        "row_count": 200,
        "column_count": 15,
        "file_size_mb": 0.5,
        "data_dictionary_url": "https://www.casact.org/publications-research/research/research-resources/loss-reserving-data-pulled-naic-schedule-p",
        "modeling_types": ["time_series", "regression"],
        "pivot_variables": ["occurrence_date", "claim_amount"],
        "best_fit_models": ["chain_ladder", "mack", "bornhuetter_ferguson"],
    },
    {
        "name": "CAS Loss Reserving Database - Medical Malpractice",
        "description": "Triangles de sinistres responsabilitÃ© mÃ©dicale de la CAS. Branche Ã  dÃ©veloppement trÃ¨s long. Parfait pour Ã©tudier les incertitudes de provisionnement.",
        "source": "other",
        "source_url": "https://www.casact.org/publications-research/research/research-resources/loss-reserving-data-pulled-naic-schedule-p",
        "tags": ["sante", "reserving"],
        "row_count": 200,
        "column_count": 15,
        "file_size_mb": 0.5,
        "data_dictionary_url": "https://www.casact.org/publications-research/research/research-resources/loss-reserving-data-pulled-naic-schedule-p",
        "modeling_types": ["time_series", "regression"],
        "pivot_variables": ["occurrence_date", "claim_amount"],
        "best_fit_models": ["chain_ladder", "mack", "bornhuetter_ferguson"],
    },

    # ========== UCI MACHINE LEARNING REPOSITORY ==========
    {
        "name": "Statlog German Credit Data",
        "description": "Dataset classique de scoring crÃ©dit. 1000 demandeurs avec 20 attributs. TrÃ¨s utilisÃ© en formation pour les modÃ¨les de classification binaire et l'interprÃ©tabilitÃ©.",
        "source": "other",
        "source_url": "https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data",
        "tags": ["machine_learning"],
        "row_count": 1000,
        "column_count": 21,
        "file_size_mb": 0.1,
        "data_dictionary_url": "https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data",
        "modeling_types": ["classification"],
        "pivot_variables": [],
        "best_fit_models": ["glm", "xgboost", "random_forest"],
    },

    # ========== OPENDATA / INSEE ==========
    {
        "name": "INSEE - DonnÃ©es dÃ©mographiques communales 2023",
        "description": "Statistiques dÃ©mographiques par commune franÃ§aise. Population, Ã¢ge moyen, rÃ©partition H/F. Utile pour la tarification gÃ©ographique et les Ã©tudes de portefeuille.",
        "source": "insee",
        "source_url": "https://www.insee.fr/fr/statistiques/6683035",
        "tags": ["sante", "pricing"],
        "row_count": 35000,
        "column_count": 25,
        "file_size_mb": 8.0,
        "data_dictionary_url": "https://www.insee.fr/fr/statistiques/6683035",
        "modeling_types": ["classification", "clustering"],
        "pivot_variables": [],
        "best_fit_models": ["glm", "random_forest"],
    },
    {
        "name": "Data.gouv.fr - Accidents corporels de la circulation",
        "description": "Base de donnÃ©es des accidents corporels de la circulation routiÃ¨re en France. DÃ©tails sur les circonstances, vÃ©hicules et usagers impliquÃ©s. Excellent pour l'analyse des risques routiers.",
        "source": "opendata",
        "source_url": "https://www.data.gouv.fr/fr/datasets/bases-de-donnees-annuelles-des-accidents-corporels-de-la-circulation-routiere-annees-de-2005-a-2022/",
        "tags": ["iard", "machine_learning"],
        "row_count": 1500000,
        "column_count": 50,
        "file_size_mb": 200.0,
        "data_dictionary_url": "https://www.data.gouv.fr/fr/datasets/bases-de-donnees-annuelles-des-accidents-corporels-de-la-circulation-routiere-annees-de-2005-a-2022/",
        "modeling_types": ["classification", "regression"],
        "pivot_variables": ["occurrence_date", "claim_id"],
        "best_fit_models": ["xgboost", "random_forest", "lightgbm"],
    },
    {
        "name": "INSEE - Tables de mortalitÃ© franÃ§aises",
        "description": "Tables de mortalitÃ© officielles franÃ§aises par Ã¢ge et sexe. DonnÃ©es essentielles pour le calcul des provisions mathÃ©matiques en assurance vie et la tarification.",
        "source": "insee",
        "source_url": "https://www.insee.fr/fr/statistiques/6683035",
        "tags": ["vie", "pricing"],
        "row_count": 220,
        "column_count": 10,
        "file_size_mb": 0.1,
        "data_dictionary_url": "https://www.insee.fr/fr/statistiques/6683035",
        "modeling_types": ["survival", "time_series"],
        "pivot_variables": [],
        "best_fit_models": ["cox", "kaplan_meier"],
    },

    # ========== ACTUARIAL DATASETS CLASSIQUES ==========
    {
        "name": "Swedish Motor Insurance (LGPIF)",
        "description": "Dataset historique suÃ©dois de tarification automobile. Contient les zones gÃ©ographiques, classes de vÃ©hicule et sinistralitÃ©. RÃ©fÃ©rence pÃ©dagogique pour les GLM.",
        "source": "other",
        "source_url": "https://www.openml.org/search?type=data&id=574",
        "tags": ["iard", "glm", "pricing"],
        "row_count": 2182,
        "column_count": 7,
        "file_size_mb": 0.1,
        "data_dictionary_url": "https://www.openml.org/search?type=data&id=574",
        "modeling_types": ["regression"],
        "pivot_variables": ["exposure", "claim_amount"],
        "best_fit_models": ["glm"],
    },
    {
        "name": "Motorcycle Insurance Claims",
        "description": "Dataset de sinistres moto avec exposition et montants. Petit dataset pÃ©dagogique parfait pour l'introduction aux GLM Poisson et Gamma.",
        "source": "other",
        "source_url": "https://www.statsmodels.org/stable/datasets/generated/fair.html",
        "tags": ["iard", "glm", "pricing"],
        "row_count": 64,
        "column_count": 6,
        "file_size_mb": 0.01,
        "data_dictionary_url": "https://www.statsmodels.org/stable/datasets/generated/fair.html",
        "modeling_types": ["regression"],
        "pivot_variables": ["exposure", "claim_amount"],
        "best_fit_models": ["glm"],
    },
    {
        "name": "Wisconsin Breast Cancer Dataset",
        "description": "Classification de tumeurs malignes/bÃ©nignes. Dataset mÃ©dical classique utilisÃ© en actuariat santÃ© pour dÃ©montrer les modÃ¨les de classification binaire.",
        "source": "other",
        "source_url": "https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic",
        "tags": ["sante", "machine_learning"],
        "row_count": 569,
        "column_count": 32,
        "file_size_mb": 0.1,
        "data_dictionary_url": "https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic",
        "modeling_types": ["classification"],
        "pivot_variables": [],
        "best_fit_models": ["glm", "xgboost", "random_forest"],
    },
    {
        "name": "Telco Customer Churn",
        "description": "PrÃ©diction du churn (rÃ©siliation) client. Applicable Ã  l'assurance pour la rÃ©tention de portefeuille et l'analyse de la fidÃ©litÃ© client.",
        "source": "kaggle",
        "source_url": "https://www.kaggle.com/datasets/blastchar/telco-customer-churn",
        "tags": ["machine_learning"],
        "row_count": 7043,
        "column_count": 21,
        "file_size_mb": 0.5,
        "data_dictionary_url": "https://www.kaggle.com/datasets/blastchar/telco-customer-churn",
        "modeling_types": ["classification", "survival"],
        "pivot_variables": ["policy_id"],
        "best_fit_models": ["xgboost", "random_forest", "cox", "kaplan_meier"],
    },

    # ========== SURVIVAL / LIFE INSURANCE ==========
    {
        "name": "ROSSI Recidivism Dataset",
        "description": "Dataset de survie classique pour l'analyse du temps jusqu'Ã  la rÃ©cidive. UtilisÃ© pour enseigner les modÃ¨les de Cox et Kaplan-Meier.",
        "source": "other",
        "source_url": "https://vincentarelbundock.github.io/Rdatasets/doc/carData/Rossi.html",
        "tags": ["vie", "machine_learning"],
        "row_count": 432,
        "column_count": 9,
        "file_size_mb": 0.02,
        "data_dictionary_url": "https://vincentarelbundock.github.io/Rdatasets/doc/carData/Rossi.html",
        "modeling_types": ["survival"],
        "pivot_variables": [],
        "best_fit_models": ["cox", "kaplan_meier"],
    },
    {
        "name": "Heart Failure Survival Dataset",
        "description": "PrÃ©diction de la mortalitÃ© par insuffisance cardiaque. 299 patients avec variables cliniques. Parfait pour l'analyse de survie en santÃ©.",
        "source": "kaggle",
        "source_url": "https://www.kaggle.com/datasets/andrewmvd/heart-failure-clinical-data",
        "tags": ["sante", "machine_learning"],
        "row_count": 299,
        "column_count": 13,
        "file_size_mb": 0.02,
        "data_dictionary_url": "https://www.kaggle.com/datasets/andrewmvd/heart-failure-clinical-data",
        "modeling_types": ["survival", "classification"],
        "pivot_variables": [],
        "best_fit_models": ["cox", "kaplan_meier", "xgboost", "random_forest"],
    },

    # ========== REINSURANCE / CATASTROPHES ==========
    {
        "name": "EMDAT Natural Disasters Database",
        "description": "Base internationale des catastrophes naturelles depuis 1900. DÃ©cÃ¨s, dommages Ã©conomiques par Ã©vÃ©nement. Essentiel pour la modÃ©lisation Cat et la rÃ©assurance.",
        "source": "other",
        "source_url": "https://www.emdat.be/",
        "tags": ["iard", "machine_learning"],
        "row_count": 25000,
        "column_count": 45,
        "file_size_mb": 15.0,
        "data_dictionary_url": "https://www.emdat.be/classification",
        "modeling_types": ["regression", "time_series"],
        "pivot_variables": ["occurrence_date", "claim_amount"],
        "best_fit_models": ["glm", "xgboost"],
    },
]


def clear_existing_datasets():
    """Supprime tous les datasets existants pour un fresh start."""
    print("ğŸ—‘ï¸  Suppression des datasets existants...")
    try:
        # D'abord supprimer les reviews, notebooks et benchmarks (dÃ©pendances)
        supabase.table("benchmarks").delete().neq("id", "00000000-0000-0000-0000-000000000000").execute()
        supabase.table("notebooks").delete().neq("id", "00000000-0000-0000-0000-000000000000").execute()
        supabase.table("reviews").delete().neq("id", "00000000-0000-0000-0000-000000000000").execute()
        supabase.table("datasets").delete().neq("id", "00000000-0000-0000-0000-000000000000").execute()
        print("âœ… Datasets existants supprimÃ©s")
    except Exception as e:
        print(f"âš ï¸  Avertissement lors de la suppression: {e}")


def insert_datasets():
    """InsÃ¨re les vrais datasets dans Supabase."""
    print(f"\nğŸ“¦ Insertion de {len(REAL_DATASETS)} datasets actuariels...")

    success_count = 0
    error_count = 0

    for i, dataset in enumerate(REAL_DATASETS, 1):
        try:
            # PrÃ©parer les donnÃ©es
            data = {
                "name": dataset["name"],
                "description": dataset["description"],
                "source": dataset["source"],
                "source_url": dataset["source_url"],
                "tags": dataset["tags"],
                "row_count": dataset.get("row_count"),
                "column_count": dataset.get("column_count"),
                "file_size_mb": dataset.get("file_size_mb"),
                "data_dictionary_url": dataset.get("data_dictionary_url"),
                "modeling_types": dataset.get("modeling_types", []),
                "pivot_variables": dataset.get("pivot_variables", []),
                "best_fit_models": dataset.get("best_fit_models", []),
                "created_by": "system",  # Datasets systÃ¨me
            }

            # InsÃ©rer dans Supabase
            result = supabase.table("datasets").insert(data).execute()

            if result.data:
                success_count += 1
                print(f"  âœ… [{i}/{len(REAL_DATASETS)}] {dataset['name'][:50]}...")
            else:
                error_count += 1
                print(f"  âŒ [{i}/{len(REAL_DATASETS)}] {dataset['name'][:50]} - Pas de donnÃ©es retournÃ©es")

        except Exception as e:
            error_count += 1
            print(f"  âŒ [{i}/{len(REAL_DATASETS)}] {dataset['name'][:50]} - Erreur: {e}")

    return success_count, error_count


def main():
    """Point d'entrÃ©e principal."""
    print("=" * 60)
    print("ğŸš€ StochastiQdata - Peuplement avec vrais datasets actuariels")
    print("=" * 60)
    print(f"\nğŸ“Š {len(REAL_DATASETS)} datasets Ã  insÃ©rer")
    print("ğŸ“ Sources: Kaggle, CAS, UCI, INSEE, OpenData, autres")
    print("-" * 60)

    # Option pour nettoyer d'abord
    if len(sys.argv) > 1 and sys.argv[1] == "--clean":
        clear_existing_datasets()

    # InsÃ©rer les datasets
    success, errors = insert_datasets()

    # RÃ©sumÃ©
    print("\n" + "=" * 60)
    print("ğŸ“Š RÃ‰SUMÃ‰")
    print("=" * 60)
    print(f"  âœ… SuccÃ¨s: {success}")
    print(f"  âŒ Erreurs: {errors}")
    print(f"  ğŸ“¦ Total: {len(REAL_DATASETS)}")
    print("=" * 60)

    if errors == 0:
        print("\nğŸ‰ Tous les datasets ont Ã©tÃ© insÃ©rÃ©s avec succÃ¨s!")
    else:
        print(f"\nâš ï¸  {errors} erreur(s) rencontrÃ©e(s). VÃ©rifiez les logs ci-dessus.")

    return 0 if errors == 0 else 1


if __name__ == "__main__":
    sys.exit(main())
